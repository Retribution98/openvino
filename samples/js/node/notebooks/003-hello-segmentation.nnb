{
    "cells": [
        {
            "language": "markdown",
            "source": [
                "# Hello Image Segmentation\n\nA very basic introduction to using segmentation models with OpenVINOâ„¢.\nIn this tutorial, a pre-trained [road-segmentation-adas-0001](https://docs.openvino.ai/2023.0/omz_models_model_road_segmentation_adas_0001.html) model from the [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/) is used. ADAS stands for Advanced Driver Assistance Services. The model recognizes four classes: background, road, curb and mark.\n"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Imports"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "const {\n  getImageData, \n  displayArrayAsImage, \n  arrayToImageData,\n  transform,\n  downloadFile,\n} = require('../helpers');\n\nconst cv2 = require('opencv.js');\nconst { display } = require('node-kernel');\n\nconst ov = require('../node_modules/openvinojs-node/build/Release/ov_node_addon.node');  // Later user would be able to download ov_node_addon using npm"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "const baseArtifactsDir = '../../assets/models';\n\nconst modelName = 'road-segmentation-adas-0001';\nconst modelXMLName = `${modelName}.xml`;\nconst modelBINName = `${modelName}.bin`;\n\nconst modelXMLPath = baseArtifactsDir + '/' + modelXMLName;\n\nconst baseURL = 'https://storage.openvinotoolkit.org/repositories/open_model_zoo/2022.3/models_bin/1/road-segmentation-adas-0001/FP32/';\n\n\nawait downloadFile(baseURL + modelXMLName, modelXMLName, baseArtifactsDir);\nawait downloadFile(baseURL + modelBINName, modelBINName, baseArtifactsDir);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "File successfully stored at '../../assets/models/road-segmentation-adas-0001.xml'",
                                "File successfully stored at '../../assets/models/road-segmentation-adas-0001.bin'",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "markdown",
            "source": [
                "## Load the Model"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "const core = new ov.Core();\nconst model = core.read_model(modelXMLPath);\nconst compiledModel = core.compile_model(model, 'CPU');\n\nconst inputLayer = compiledModel.input(0);\nconst outputLayer = compiledModel.output(0);"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Load an Image\n\nA sample image from the [Mapillary Vistas](https://www.mapillary.com/dataset/vistas) dataset is provided. "
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "const imgData = await getImageData('../../assets/images/empty_road_mapillary.jpg');\n\nconst originalImage = cv2.matFromImageData(imgData);\nconst { cols: originalWidth, rows: originalHeight } = originalImage;\n\nconst image = new cv2.Mat();\ncv2.cvtColor(originalImage, image, cv2.COLOR_RGBA2RGB);\ncv2.cvtColor(image, image, cv2.COLOR_BGR2RGB); \n\nconst [B, C, H, W] = inputLayer.shape;\n\ncv2.resize(image, image, new cv2.Size(W, H));\n\nconst inputImage = transform(image.data, { width: W, height: H }, [0, 1, 2]); // NHWC to NCHW\n\ndisplayArrayAsImage(originalImage.data, originalWidth, originalHeight, display);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.error",
                            "value": {
                                "name": "TypeError",
                                "message": "cv2.Mat is not a constructor",
                                "stack": "    at transform (/home/nvishnya/Code/wasm-openvino/samples/js/node/helpers.js:92:15)\n    at <Cell 8> [14, 0]\n    at processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async C (/home/nvishnya/.vscode-server/extensions/donjayamanne.typescript-notebook-2.0.6/out/extension/server/index.js:2:113337)\n    at async t.execCode (/home/nvishnya/.vscode-server/extensions/donjayamanne.typescript-notebook-2.0.6/out/extension/server/index.js:2:114306)"
                            }
                        }
                    ]
                }
            ]
        },
        {
            "language": "markdown",
            "source": [
                "## Do Inference"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "const tensor_data = new Float32Array(inputImage);\nconst tensor = new ov.Tensor(ov.element.f32, inputLayer.shape, tensor_data);\n\nconst inferRequest = compiledModel.create_infer_request();\ninferRequest.set_input_tensor(tensor);\ninferRequest.infer();\n\nconst output = inferRequest.getTensor(outputLayer);\n\nconst { data: outputData } = output;\nconst layers = { bg: [], c: [], h: [], w: [] };\nconst resultLayer = [];\nconst colormap = [[68, 1, 84, 255], [48, 103, 141, 255], [53, 183, 120, 255], [199, 216, 52, 255]];\n\nconst size = outputData.length/4;\n\nfor (let i = 0; i < size; i++) {\n  const valueAt = (i, number) => outputData[i + number*size];\n\n  const currentValues = { \n    bg: valueAt(i, 0),\n    c: valueAt(i, 1),\n    h: valueAt(i, 2),\n    w: valueAt(i, 3),\n  };\n  const values = Object.values(currentValues);\n  const maxIndex = values.indexOf(Math.max(...values));\n\n  resultLayer.push(maxIndex);\n}\n\nconst pixels = [];\nresultLayer.forEach(i => pixels.push(...colormap[i]));\n\ndisplayArrayAsImage(pixels, W, H, display);\n"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Visualize data"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "const alpha = 0.3;\n\nconst pixelsAsImageData = arrayToImageData(pixels, W, H);\nconst mask = cv2.matFromImageData(pixelsAsImageData);\n\ncv2.resize(mask, mask, new cv2.Size(originalWidth, originalHeight));\n\ncv2.addWeighted(mask, alpha, originalImage, 1 - alpha, 0, mask);\n\ndisplayArrayAsImage(mask.data, originalWidth, originalHeight, display);"
            ],
            "outputs": []
        }
    ]
}